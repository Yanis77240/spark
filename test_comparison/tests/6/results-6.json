{
  "  org.apache.spark.util.kvstore.InMemoryStoreSuite": {
    "attributes": {
      "Succeeded": 6.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.util.kvstore.ArrayWrappersSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.util.kvstore.LevelDBIteratorSuite": {
    "attributes": {
      "Succeeded": 38.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.util.kvstore.InMemoryIteratorSuite": {
    "attributes": {
      "Succeeded": 38.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.util.kvstore.LevelDBTypeInfoSuite": {
    "attributes": {
      "Succeeded": 10.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.util.kvstore.LevelDBSuite": {
    "attributes": {
      "Succeeded": 8.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.util.TransportFrameDecoderSuite": {
    "attributes": {
      "Succeeded": 6.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.util.NettyMemoryMetricsSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.util.CryptoUtilsSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.TransportResponseHandlerSuite": {
    "attributes": {
      "Succeeded": 8.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.TransportClientFactorySuite": {
    "attributes": {
      "Succeeded": 6.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.protocol.MessageWithHeaderSuite": {
    "attributes": {
      "Succeeded": 4.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.crypto.AuthEngeSuite": {
    "attributes": {
      "Succeeded": 7.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.crypto.AuthMessagesSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.crypto.AuthIntegrationSuite": {
    "attributes": {
      "Succeeded": 6.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.sasl.SparkSaslSuite": {
    "attributes": {
      "Succeeded": 11.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.server.OneForOneStreamManagerSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.ProtocolSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.TransportRequestHandlerSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.RequestTimeoutIntegrationSuite": {
    "attributes": {
      "Succeeded": 3.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.StreamSuite": {
    "attributes": {
      "Succeeded": 4.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.ChunkFetchIntegrationSuite": {
    "attributes": {
      "Succeeded": 5.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.RpcIntegrationSuite": {
    "attributes": {
      "Succeeded": 7.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.sasl.SaslIntegrationSuite": {
    "attributes": {
      "Succeeded": 5.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.sasl.ShuffleSecretManagerSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.shuffle.RetrygBlockFetcherSuite": {
    "attributes": {
      "Succeeded": 7.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.shuffle.ExternalShuffleSecuritySuite": {
    "attributes": {
      "Succeeded": 4.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.shuffle.ExternalShuffleBlockHandlerSuite": {
    "attributes": {
      "Succeeded": 3.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.shuffle.ExternalShuffleIntegrationSuite": {
    "attributes": {
      "Succeeded": 8.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.shuffle.ExternalShuffleBlockResolverSuite": {
    "attributes": {
      "Succeeded": 3.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.shuffle.OneForOneBlockFetcherSuite": {
    "attributes": {
      "Succeeded": 5.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.shuffle.ExternalShuffleCleanupSuite": {
    "attributes": {
      "Succeeded": 4.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.network.shuffle.BlockTransferMessagesSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.unsafe.types.UTF8StrgSuite": {
    "attributes": {
      "Succeeded": 38.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.unsafe.types.CalendarIntervalSuite": {
    "attributes": {
      "Succeeded": 9.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.unsafe.array.LongArraySuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.unsafe.PlatformUtilSuite": {
    "attributes": {
      "Succeeded": 7.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.unsafe.hash.Murmur3_x86_32Suite": {
    "attributes": {
      "Succeeded": 6.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.launcher.InProcessLauncherSuite": {
    "attributes": {
      "Succeeded": 3.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.launcher.LauncherServerSuite": {
    "attributes": {
      "Succeeded": 5.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.launcher.CommandBuilderUtilsSuite": {
    "attributes": {
      "Succeeded": 5.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.launcher.SparkSubmitCommandBuilderSuite": {
    "attributes": {
      "Succeeded": 12.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.launcher.ChildProcAppHandleSuite": {
    "attributes": {
      "Succeeded": 11.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.launcher.SparkSubmitOptionParserSuite": {
    "attributes": {
      "Succeeded": 4.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorterRadixSortSuite": {
    "attributes": {
      "Succeeded": 13.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorterSuite": {
    "attributes": {
      "Succeeded": 13.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.util.collection.unsafe.sort.UnsafeInMemorySorterSuite": {
    "attributes": {
      "Succeeded": 3.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.util.collection.unsafe.sort.UnsafeInMemorySorterRadixSortSuite": {
    "attributes": {
      "Succeeded": 3.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.api.java.OptionalSuite": {
    "attributes": {
      "Succeeded": 8.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.io.ReadAheadInputStreamSuite": {
    "attributes": {
      "Succeeded": 7.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.io.NioBufferedInputStreamSuite": {
    "attributes": {
      "Succeeded": 7.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.unsafe.map.BytesToBytesMapOffHeapSuite": {
    "attributes": {
      "Succeeded": 13.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.unsafe.map.BytesToBytesMapOnHeapSuite": {
    "attributes": {
      "Succeeded": 13.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.shuffle.sort.PackedRecordPoterSuite": {
    "attributes": {
      "Succeeded": 6.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.shuffle.sort.ShuffleInMemoryRadixSorterSuite": {
    "attributes": {
      "Succeeded": 3.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.shuffle.sort.ShuffleInMemorySorterSuite": {
    "attributes": {
      "Succeeded": 3.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.shuffle.sort.UnsafeShuffleWriterSuite": {
    "attributes": {
      "Succeeded": 25.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.memory.TaskMemoryManagerSuite": {
    "attributes": {
      "Succeeded": 10.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.JavaJdbcRDDSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.launcher.SparkLauncherSuite": {
    "attributes": {
      "Succeeded": 3.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  test.org.apache.spark.Java8RDDAPISuite": {
    "attributes": {
      "Succeeded": 18.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  test.org.apache.spark.JavaAPISuite": {
    "attributes": {
      "Succeeded": 90.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  test.org.apache.spark.JavaSparkContextSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.streamg.JavaDurationSuite": {
    "attributes": {
      "Succeeded": 11.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.streamg.JavaWriteAheadLogSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.streamg.JavaMapWithStateSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.streamg.JavaReceiverAPISuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.streamg.JavaTimeSuite": {
    "attributes": {
      "Succeeded": 7.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  test.org.apache.spark.streamg.Java8APISuite": {
    "attributes": {
      "Succeeded": 26.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  test.org.apache.spark.streamg.JavaAPISuite": {
    "attributes": {
      "Succeeded": 53.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.sql.streamg.JavaOutputModeSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.sql.streamg.JavaGroupStateTimeoutSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.sql.catalyst.expressions.XXH64Suite": {
    "attributes": {
      "Succeeded": 6.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.sql.catalyst.expressions.RowBasedKeyValueBatchSuite": {
    "attributes": {
      "Succeeded": 10.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.sql.catalyst.expressions.HiveHasherSuite": {
    "attributes": {
      "Succeeded": 6.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  test.org.apache.spark.sql.JavaDatasetAggregatorSuite": {
    "attributes": {
      "Succeeded": 5.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  test.org.apache.spark.sql.execution.sort.RecordBaryComparatorSuite": {
    "attributes": {
      "Succeeded": 8.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  test.org.apache.spark.sql.JavaDatasetSuite": {
    "attributes": {
      "Succeeded": 31.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  test.org.apache.spark.sql.JavaBeanWithArraySuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  test.org.apache.spark.sql.JavaUDAFSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  test.org.apache.spark.sql.JavaDataFrameSuite": {
    "attributes": {
      "Succeeded": 21.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  test.org.apache.spark.sql.JavaDataFrameReaderWriterSuite": {
    "attributes": {
      "Succeeded": 9.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  test.org.apache.spark.sql.JavaUDFSuite": {
    "attributes": {
      "Succeeded": 6.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  test.org.apache.spark.sql.JavaSaveLoadSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  test.org.apache.spark.sql.JavaRowSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  test.org.apache.spark.sql.JavaApplySchemaSuite": {
    "attributes": {
      "Succeeded": 3.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  test.org.apache.spark.sql.Java8DatasetAggregatorSuite": {
    "attributes": {
      "Succeeded": 4.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.stat.JavaStatisticsSuite": {
    "attributes": {
      "Succeeded": 4.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.util.JavaMLUtilsSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.fpm.JavaAssociationRulesSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.fpm.JavaPrefixSpanSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.fpm.JavaFPGrowthSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.feature.JavaWord2VecSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.feature.JavaTfIdfSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.clusterg.JavaStreamgKMeansSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.clusterg.JavaKMeansSuite": {
    "attributes": {
      "Succeeded": 3.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.clusterg.JavaLDASuite": {
    "attributes": {
      "Succeeded": 4.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.clusterg.JavaGaussianMixtureSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.clusterg.JavaBisectgKMeansSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.evaluation.JavaRankgMetricsSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.recommendation.JavaALSSuite": {
    "attributes": {
      "Succeeded": 6.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.regression.JavaStreamgLearRegressionSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.regression.JavaLearRegressionSuite": {
    "attributes": {
      "Succeeded": 3.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.regression.JavaLassoSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.regression.JavaRidgeRegressionSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.regression.JavaIsotonicRegressionSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.lalg.JavaMatricesSuite": {
    "attributes": {
      "Succeeded": 6.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.lalg.JavaVectorsSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.lalg.distributed.JavaRowMatrixSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.tree.JavaDecisionTreeSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.classification.JavaStreamgLogisticRegressionSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.classification.JavaNaiveBayesSuite": {
    "attributes": {
      "Succeeded": 4.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.classification.JavaSVMSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.classification.JavaLogisticRegressionSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.mllib.random.JavaRandomRDDsSuite": {
    "attributes": {
      "Succeeded": 14.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.stat.JavaSummarizerSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.util.JavaDefaultReadWriteSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.param.JavaParamsSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.feature.JavaPolynomialExpansionSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.feature.JavaPCASuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.feature.JavaDCTSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.feature.JavaBucketizerSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.feature.JavaTokenizerSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.feature.JavaStrgIndexerSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.feature.JavaWord2VecSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.feature.JavaVectorIndexerSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.feature.JavaVectorAssemblerSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.feature.JavaStandardScalerSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.feature.JavaVectorSlicerSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.feature.JavaStopWordsRemoverSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.feature.JavaNormalizerSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.feature.JavaHashgTFSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.source.libsvm.JavaLibSVMRelationSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.clusterg.JavaKMeansSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.tung.JavaCrossValidatorSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.JavaPipeleSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.attribute.JavaAttributeSuite": {
    "attributes": {
      "Succeeded": 4.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.attribute.JavaAttributeGroupSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.regression.JavaLearRegressionSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.regression.JavaRandomForestRegressorSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.regression.JavaGBTRegressorSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.regression.JavaDecisionTreeRegressorSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.lalg.JavaSQLDataTypesSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.classification.JavaDecisionTreeClassifierSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.classification.JavaGBTClassifierSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.classification.JavaNaiveBayesSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.classification.JavaMultilayerPerceptronClassifierSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.classification.JavaOneVsRestSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.classification.JavaLogisticRegressionSuite": {
    "attributes": {
      "Succeeded": 4.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.ml.classification.JavaRandomForestClassifierSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.sql.hive.JavaDataFrameSuite": {
    "attributes": {
      "Succeeded": 2.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.sql.hive.JavaMetastoreDataSourcesSuite": {
    "attributes": {
      "Succeeded": 3.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.streamg.kafka010.JavaConsumerStrategySuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.streamg.kafka010.JavaLocationStrategySuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.streamg.kafka010.JavaDirectKafkaStreamSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.streamg.kafka010.JavaKafkaRDDSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.streamg.flume.JavaFlumeStreamSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "  org.apache.spark.streamg.flume.JavaFlumePollgStreamSuite": {
    "attributes": {
      "Succeeded": 1.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "org.apache.hadoop.util.TestReadWriteDiskValidator": {
    "attributes": {
      "Succeeded": NaN,
      "Failed": NaN,
      "Skipped": NaN,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      "testReadWriteDiskValidator",
      "testCheckFailures"
    ]
  },
  "org.apache.hadoop.io.compress.TestCompressorDecompressor": {
    "attributes": {
      "Succeeded": NaN,
      "Failed": NaN,
      "Skipped": NaN,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      "testCompressorDecompressor",
      "testCompressorDecompressorWithExeedBufferLimit"
    ]
  },
  "org.apache.hadoop.io.compress.snappy.TestSnappyCompressorDecompressor": {
    "attributes": {
      "Succeeded": NaN,
      "Failed": NaN,
      "Skipped": NaN,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      "testSnappyCompressDecompressInMultiThreads",
      "testSnappyCompressDecompress"
    ]
  },
  "org.apache.hadoop.security.TestLdapGroupsMapping": {
    "attributes": {
      "Succeeded": NaN,
      "Failed": NaN,
      "Skipped": NaN,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      "testLdapReadTimeout",
      "testLdapConnectionTimeout"
    ]
  },
  "org.apache.hadoop.hdfs.TestFileChecksum": {
    "attributes": {
      "Succeeded": NaN,
      "Failed": NaN,
      "Skipped": NaN,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      "testStripedFileChecksumWithMissedDataBlocksRangeQuery10",
      "testStripedFileChecksumWithMissedDataBlocksRangeQuery12",
      "testStripedFileChecksumWithMissedDataBlocksRangeQuery13",
      "testStripedFileChecksumWithMissedDataBlocksRangeQuery14",
      "testStripedFileChecksumWithMissedDataBlocksRangeQuery15",
      "testStripedFileChecksumWithMissedDataBlocksRangeQuery16",
      "testStripedFileChecksumWithMissedDataBlocksRangeQuery20",
      "testStripedFileChecksumWithMissedDataBlocks1",
      "testStripedFileChecksumWithMissedDataBlocks2",
      "testStripedFileChecksumWithMissedDataBlocksRangeQuery8",
      "testStripedFileChecksumWithMissedDataBlocksRangeQuery9"
    ]
  },
  "org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc": {
    "attributes": {
      "Succeeded": NaN,
      "Failed": NaN,
      "Skipped": NaN,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      "testStripedFileChecksumWithMissedDataBlocksRangeQuery13",
      "testStripedFileChecksumWithMissedDataBlocksRangeQuery14",
      "testStripedFileChecksumWithMissedDataBlocksRangeQuery15",
      "testStripedFileChecksumWithMissedDataBlocks1",
      "testStripedFileChecksumWithMissedDataBlocks2",
      "testStripedFileChecksumWithMissedDataBlocksRangeQuery3"
    ]
  },
  "org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy": {
    "attributes": {
      "Succeeded": NaN,
      "Failed": NaN,
      "Skipped": NaN,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      "testRecoverAnyBlocks1",
      "testRecoverOneDataBlock",
      "testRecoverOneParityBlock"
    ]
  },
  "org.apache.hadoop.mapred.TestMRTimelineEventHandling": {
    "attributes": {
      "Succeeded": NaN,
      "Failed": NaN,
      "Skipped": NaN,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      "testMRNewTimelineServiceEventHandling"
    ]
  },
  "nodeFile null": {
    "attributes": {
      "Succeeded": NaN,
      "Failed": NaN,
      "Skipped": NaN,
      "Pending": NaN,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      "testSimulatorRunning[Testing with: SYNTH, org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler, "
    ]
  },
  "assembly": {
    "attributes": {
      "Succeeded": 0.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "core": {
    "attributes": {
      "Succeeded": 2096.0,
      "Failed": 2.0,
      "Skipped": 9.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      "- download remote resource if it is not supported by yarn service *** FAILED ***",
      "- Testing test test core *** FAILED ***"
    ]
  },
  "examples": {
    "attributes": {
      "Succeeded": 0.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "graphx": {
    "attributes": {
      "Succeeded": 110.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "launcher": {
    "attributes": {
      "Succeeded": 0.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "mllib-local": {
    "attributes": {
      "Succeeded": 84.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "mllib": {
    "attributes": {
      "Succeeded": 1329.0,
      "Failed": 0.0,
      "Skipped": 7.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "repl": {
    "attributes": {
      "Succeeded": 35.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "streaming": {
    "attributes": {
      "Succeeded": 334.0,
      "Failed": 0.0,
      "Skipped": 1.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "tools": {
    "attributes": {
      "Succeeded": 0.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "common/kvstore": {
    "attributes": {
      "Succeeded": 0.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "common/network-common": {
    "attributes": {
      "Succeeded": 0.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "common/network-shuffle": {
    "attributes": {
      "Succeeded": 0.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "common/network-yarn": {
    "attributes": {
      "Succeeded": 0.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "common/sketch": {
    "attributes": {
      "Succeeded": 29.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "common/tags": {
    "attributes": {
      "Succeeded": 0.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "common/unsafe": {
    "attributes": {
      "Succeeded": 19.0,
      "Failed": 0.0,
      "Skipped": 1.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "external/flume-assembly": {
    "attributes": {
      "Succeeded": 0.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "external/flume-sink": {
    "attributes": {
      "Succeeded": 5.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "external/flume": {
    "attributes": {
      "Succeeded": 4.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "external/kafka-0-10-assembly": {
    "attributes": {
      "Succeeded": 0.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "external/kafka-0-10-sql": {
    "attributes": {
      "Succeeded": 105.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "external/kafka-0-10": {
    "attributes": {
      "Succeeded": 15.0,
      "Failed": 0.0,
      "Skipped": 0.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "sql/catalyst": {
    "attributes": {
      "Succeeded": 2611.0,
      "Failed": 1.0,
      "Skipped": 2.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      "- daysToMillis and millisToDays *** FAILED ***"
    ]
  },
  "sql/core": {
    "attributes": {
      "Succeeded": 4109.0,
      "Failed": 1.0,
      "Skipped": 59.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      "- SPARK-6330 regression test *** FAILED ***"
    ]
  },
  "sql/hive": {
    "attributes": {
      "Succeeded": 2343.0,
      "Failed": 511.0,
      "Skipped": 595.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      "- SPARK-22745 - read Hive's statistics for partition *** FAILED ***",
      "- SPARK-22745 - testing test test sql hive *** FAILED ***",
      "- alter table rename after analyze table *** FAILED ***",
      "- alter table SET TBLPROPERTIES after analyze table *** FAILED ***",
      "- alter table UNSET TBLPROPERTIES after analyze table *** FAILED ***",
      "- success sanity check *** FAILED ***",
      "- hadoop configuration preserved *** FAILED ***",
      "- 0.12: create client *** FAILED ***",
      "- 0.12: createDatabase *** FAILED ***",
      "- 0.12: createDatabase with null description *** FAILED ***",
      "- 0.12: setCurrentDatabase *** FAILED ***",
      "- 0.12: getDatabase *** FAILED ***",
      "- 0.12: databaseExists *** FAILED ***",
      "- 0.12: listDatabases *** FAILED ***",
      "- 0.12: alterDatabase *** FAILED ***",
      "- 0.12: dropDatabase *** FAILED ***",
      "- 0.12: createTable *** FAILED ***",
      "- 0.12: loadTable *** FAILED ***",
      "- 0.12: tableExists *** FAILED ***",
      "- 0.12: getTable *** FAILED ***",
      "- 0.12: getTableOption *** FAILED ***",
      "- 0.12: alterTable(table: CatalogTable) *** FAILED ***",
      "- 0.12: alterTable(dbName: String, tableName: String, table: CatalogTable) *** FAILED ***",
      "- 0.12: alterTable - rename *** FAILED ***",
      "- 0.12: alterTable - change database *** FAILED ***",
      "- 0.12: alterTable - change database and table names *** FAILED ***",
      "- 0.12: listTables(database) *** FAILED ***",
      "- 0.12: listTables(database, pattern) *** FAILED ***",
      "- 0.12: dropTable *** FAILED ***",
      "- 0.12: sql create partitioned table *** FAILED ***",
      "- 0.12: createPartitions *** FAILED ***",
      "- 0.12: getPartitionNames(catalogTable) *** FAILED ***",
      "- 0.12: getPartitions(catalogTable) *** FAILED ***",
      "- 0.12: getPartitionsByFilter *** FAILED ***",
      "- 0.12: getPartition *** FAILED ***",
      "- 0.12: getPartitionOption(db: String, table: String, spec: TablePartitionSpec) *** FAILED ***",
      "- 0.12: getPartitionOption(table: CatalogTable, spec: TablePartitionSpec) *** FAILED ***",
      "- 0.12: getPartitions(db: String, table: String) *** FAILED ***",
      "- 0.12: loadPartition *** FAILED ***",
      "- 0.12: loadDynamicPartitions *** FAILED ***",
      "- 0.12: renamePartitions *** FAILED ***",
      "- 0.12: alterPartitions *** FAILED ***",
      "- 0.12: dropPartitions *** FAILED ***",
      "- 0.12: createFunction *** FAILED ***",
      "- 0.12: functionExists *** FAILED ***",
      "- 0.12: renameFunction *** FAILED ***",
      "- 0.12: alterFunction *** FAILED ***",
      "- 0.12: getFunction *** FAILED ***",
      "- 0.12: getFunctionOption *** FAILED ***",
      "- 0.12: listFunctions *** FAILED ***",
      "- 0.12: dropFunction *** FAILED ***",
      "- 0.12: sql set command *** FAILED ***",
      "- 0.12: sql create index and reset *** FAILED ***",
      "- 0.12: version *** FAILED ***",
      "- 0.12: getConf *** FAILED ***",
      "- 0.12: setOut *** FAILED ***",
      "- 0.12: setInfo *** FAILED ***",
      "- 0.12: setError *** FAILED ***",
      "- 0.12: newSession *** FAILED ***",
      "- 0.12: withHiveState and addJar *** FAILED ***",
      "- 0.12: reset *** FAILED ***",
      "- 0.12: CREATE TABLE AS SELECT *** FAILED ***",
      "- 0.12: Delete the temporary staging directory and files after each insert *** FAILED ***",
      "- 0.12: SPARK-13709: reading partitioned Avro table with nested schema *** FAILED ***",
      "- 0.12: CTAS for managed data source tables *** FAILED ***",
      "- 0.12: Decimal support of Avro Hive serde *** FAILED ***",
      "- 0.12: read avro file containing decimal *** FAILED ***",
      "- 0.12: SPARK-17920: Insert into/overwrite avro table *** FAILED ***",
      "- 0.13: create client *** FAILED ***",
      "- 0.13: createDatabase *** FAILED ***",
      "- 0.13: createDatabase with null description *** FAILED ***",
      "- 0.13: setCurrentDatabase *** FAILED ***",
      "- 0.13: getDatabase *** FAILED ***",
      "- 0.13: databaseExists *** FAILED ***",
      "- 0.13: listDatabases *** FAILED ***",
      "- 0.13: alterDatabase *** FAILED ***",
      "- 0.13: dropDatabase *** FAILED ***",
      "- 0.13: createTable *** FAILED ***",
      "- 0.13: loadTable *** FAILED ***",
      "- 0.13: tableExists *** FAILED ***",
      "- 0.13: getTable *** FAILED ***",
      "- 0.13: getTableOption *** FAILED ***",
      "- 0.13: alterTable(table: CatalogTable) *** FAILED ***",
      "- 0.13: alterTable(dbName: String, tableName: String, table: CatalogTable) *** FAILED ***",
      "- 0.13: alterTable - rename *** FAILED ***",
      "- 0.13: alterTable - change database *** FAILED ***",
      "- 0.13: alterTable - change database and table names *** FAILED ***",
      "- 0.13: listTables(database) *** FAILED ***",
      "- 0.13: listTables(database, pattern) *** FAILED ***",
      "- 0.13: dropTable *** FAILED ***",
      "- 0.13: sql create partitioned table *** FAILED ***",
      "- 0.13: createPartitions *** FAILED ***",
      "- 0.13: getPartitionNames(catalogTable) *** FAILED ***",
      "- 0.13: getPartitions(catalogTable) *** FAILED ***",
      "- 0.13: getPartitionsByFilter *** FAILED ***",
      "- 0.13: getPartition *** FAILED ***",
      "- 0.13: getPartitionOption(db: String, table: String, spec: TablePartitionSpec) *** FAILED ***",
      "- 0.13: getPartitionOption(table: CatalogTable, spec: TablePartitionSpec) *** FAILED ***",
      "- 0.13: getPartitions(db: String, table: String) *** FAILED ***",
      "- 0.13: loadPartition *** FAILED ***",
      "- 0.13: loadDynamicPartitions *** FAILED ***",
      "- 0.13: renamePartitions *** FAILED ***",
      "- 0.13: alterPartitions *** FAILED ***",
      "- 0.13: dropPartitions *** FAILED ***",
      "- 0.13: createFunction *** FAILED ***",
      "- 0.13: functionExists *** FAILED ***",
      "- 0.13: renameFunction *** FAILED ***",
      "- 0.13: alterFunction *** FAILED ***",
      "- 0.13: getFunction *** FAILED ***",
      "- 0.13: getFunctionOption *** FAILED ***",
      "- 0.13: listFunctions *** FAILED ***",
      "- 0.13: dropFunction *** FAILED ***",
      "- 0.13: sql set command *** FAILED ***",
      "- 0.13: sql create index and reset *** FAILED ***",
      "- 0.13: version *** FAILED ***",
      "- 0.13: getConf *** FAILED ***",
      "- 0.13: setOut *** FAILED ***",
      "- 0.13: setInfo *** FAILED ***",
      "- 0.13: setError *** FAILED ***",
      "- 0.13: newSession *** FAILED ***",
      "- 0.13: withHiveState and addJar *** FAILED ***",
      "- 0.13: reset *** FAILED ***",
      "- 0.13: CREATE TABLE AS SELECT *** FAILED ***",
      "- 0.13: Delete the temporary staging directory and files after each insert *** FAILED ***",
      "- 0.13: SPARK-13709: reading partitioned Avro table with nested schema *** FAILED ***",
      "- 0.13: CTAS for managed data source tables *** FAILED ***",
      "- 0.13: Decimal support of Avro Hive serde *** FAILED ***",
      "- 0.13: read avro file containing decimal *** FAILED ***",
      "- 0.13: SPARK-17920: Insert into/overwrite avro table *** FAILED ***",
      "- 0.14: create client *** FAILED ***",
      "- 0.14: createDatabase *** FAILED ***",
      "- 0.14: createDatabase with null description *** FAILED ***",
      "- 0.14: setCurrentDatabase *** FAILED ***",
      "- 0.14: getDatabase *** FAILED ***",
      "- 0.14: databaseExists *** FAILED ***",
      "- 0.14: listDatabases *** FAILED ***",
      "- 0.14: alterDatabase *** FAILED ***",
      "- 0.14: dropDatabase *** FAILED ***",
      "- 0.14: createTable *** FAILED ***",
      "- 0.14: loadTable *** FAILED ***",
      "- 0.14: tableExists *** FAILED ***",
      "- 0.14: getTable *** FAILED ***",
      "- 0.14: getTableOption *** FAILED ***",
      "- 0.14: alterTable(table: CatalogTable) *** FAILED ***",
      "- 0.14: alterTable(dbName: String, tableName: String, table: CatalogTable) *** FAILED ***",
      "- 0.14: alterTable - rename *** FAILED ***",
      "- 0.14: alterTable - change database *** FAILED ***",
      "- 0.14: alterTable - change database and table names *** FAILED ***",
      "- 0.14: listTables(database) *** FAILED ***",
      "- 0.14: listTables(database, pattern) *** FAILED ***",
      "- 0.14: dropTable *** FAILED ***",
      "- 0.14: sql create partitioned table *** FAILED ***",
      "- 0.14: createPartitions *** FAILED ***",
      "- 0.14: getPartitionNames(catalogTable) *** FAILED ***",
      "- 0.14: getPartitions(catalogTable) *** FAILED ***",
      "- 0.14: getPartitionsByFilter *** FAILED ***",
      "- 0.14: getPartition *** FAILED ***",
      "- 0.14: getPartitionOption(db: String, table: String, spec: TablePartitionSpec) *** FAILED ***",
      "- 0.14: getPartitionOption(table: CatalogTable, spec: TablePartitionSpec) *** FAILED ***",
      "- 0.14: getPartitions(db: String, table: String) *** FAILED ***",
      "- 0.14: loadPartition *** FAILED ***",
      "- 0.14: loadDynamicPartitions *** FAILED ***",
      "- 0.14: renamePartitions *** FAILED ***",
      "- 0.14: alterPartitions *** FAILED ***",
      "- 0.14: dropPartitions *** FAILED ***",
      "- 0.14: createFunction *** FAILED ***",
      "- 0.14: functionExists *** FAILED ***",
      "- 0.14: renameFunction *** FAILED ***",
      "- 0.14: alterFunction *** FAILED ***",
      "- 0.14: getFunction *** FAILED ***",
      "- 0.14: getFunctionOption *** FAILED ***",
      "- 0.14: listFunctions *** FAILED ***",
      "- 0.14: dropFunction *** FAILED ***",
      "- 0.14: sql set command *** FAILED ***",
      "- 0.14: sql create index and reset *** FAILED ***",
      "- 0.14: version *** FAILED ***",
      "- 0.14: getConf *** FAILED ***",
      "- 0.14: setOut *** FAILED ***",
      "- 0.14: setInfo *** FAILED ***",
      "- 0.14: setError *** FAILED ***",
      "- 0.14: newSession *** FAILED ***",
      "- 0.14: withHiveState and addJar *** FAILED ***",
      "- 0.14: reset *** FAILED ***",
      "- 0.14: CREATE TABLE AS SELECT *** FAILED ***",
      "- 0.14: Delete the temporary staging directory and files after each insert *** FAILED ***",
      "- 0.14: SPARK-13709: reading partitioned Avro table with nested schema *** FAILED ***",
      "- 0.14: CTAS for managed data source tables *** FAILED ***",
      "- 0.14: Decimal support of Avro Hive serde *** FAILED ***",
      "- 0.14: read avro file containing decimal *** FAILED ***",
      "- 0.14: SPARK-17920: Insert into/overwrite avro table *** FAILED ***",
      "- 1.0: create client *** FAILED ***",
      "- 1.0: createDatabase *** FAILED ***",
      "- 1.0: createDatabase with null description *** FAILED ***",
      "- 1.0: setCurrentDatabase *** FAILED ***",
      "- 1.0: getDatabase *** FAILED ***",
      "- 1.0: databaseExists *** FAILED ***",
      "- 1.0: listDatabases *** FAILED ***",
      "- 1.0: alterDatabase *** FAILED ***",
      "- 1.0: dropDatabase *** FAILED ***",
      "- 1.0: createTable *** FAILED ***",
      "- 1.0: loadTable *** FAILED ***",
      "- 1.0: tableExists *** FAILED ***",
      "- 1.0: getTable *** FAILED ***",
      "- 1.0: getTableOption *** FAILED ***",
      "- 1.0: alterTable(table: CatalogTable) *** FAILED ***",
      "- 1.0: alterTable(dbName: String, tableName: String, table: CatalogTable) *** FAILED ***",
      "- 1.0: alterTable - rename *** FAILED ***",
      "- 1.0: alterTable - change database *** FAILED ***",
      "- 1.0: alterTable - change database and table names *** FAILED ***",
      "- 1.0: listTables(database) *** FAILED ***",
      "- 1.0: listTables(database, pattern) *** FAILED ***",
      "- 1.0: dropTable *** FAILED ***",
      "- 1.0: sql create partitioned table *** FAILED ***",
      "- 1.0: createPartitions *** FAILED ***",
      "- 1.0: getPartitionNames(catalogTable) *** FAILED ***",
      "- 1.0: getPartitions(catalogTable) *** FAILED ***",
      "- 1.0: getPartitionsByFilter *** FAILED ***",
      "- 1.0: getPartition *** FAILED ***",
      "- 1.0: getPartitionOption(db: String, table: String, spec: TablePartitionSpec) *** FAILED ***",
      "- 1.0: getPartitionOption(table: CatalogTable, spec: TablePartitionSpec) *** FAILED ***",
      "- 1.0: getPartitions(db: String, table: String) *** FAILED ***",
      "- 1.0: loadPartition *** FAILED ***",
      "- 1.0: loadDynamicPartitions *** FAILED ***",
      "- 1.0: renamePartitions *** FAILED ***",
      "- 1.0: alterPartitions *** FAILED ***",
      "- 1.0: dropPartitions *** FAILED ***",
      "- 1.0: createFunction *** FAILED ***",
      "- 1.0: functionExists *** FAILED ***",
      "- 1.0: renameFunction *** FAILED ***",
      "- 1.0: alterFunction *** FAILED ***",
      "- 1.0: getFunction *** FAILED ***",
      "- 1.0: getFunctionOption *** FAILED ***",
      "- 1.0: listFunctions *** FAILED ***",
      "- 1.0: dropFunction *** FAILED ***",
      "- 1.0: sql set command *** FAILED ***",
      "- 1.0: sql create index and reset *** FAILED ***",
      "- 1.0: version *** FAILED ***",
      "- 1.0: getConf *** FAILED ***",
      "- 1.0: setOut *** FAILED ***",
      "- 1.0: setInfo *** FAILED ***",
      "- 1.0: setError *** FAILED ***",
      "- 1.0: newSession *** FAILED ***",
      "- 1.0: withHiveState and addJar *** FAILED ***",
      "- 1.0: reset *** FAILED ***",
      "- 1.0: CREATE TABLE AS SELECT *** FAILED ***",
      "- 1.0: Delete the temporary staging directory and files after each insert *** FAILED ***",
      "- 1.0: SPARK-13709: reading partitioned Avro table with nested schema *** FAILED ***",
      "- 1.0: CTAS for managed data source tables *** FAILED ***",
      "- 1.0: Decimal support of Avro Hive serde *** FAILED ***",
      "- 1.0: read avro file containing decimal *** FAILED ***",
      "- 1.0: SPARK-17920: Insert into/overwrite avro table *** FAILED ***",
      "- 1.1: create client *** FAILED ***",
      "- 1.1: createDatabase *** FAILED ***",
      "- 1.1: createDatabase with null description *** FAILED ***",
      "- 1.1: setCurrentDatabase *** FAILED ***",
      "- 1.1: getDatabase *** FAILED ***",
      "- 1.1: databaseExists *** FAILED ***",
      "- 1.1: listDatabases *** FAILED ***",
      "- 1.1: alterDatabase *** FAILED ***",
      "- 1.1: dropDatabase *** FAILED ***",
      "- 1.1: createTable *** FAILED ***",
      "- 1.1: loadTable *** FAILED ***",
      "- 1.1: tableExists *** FAILED ***",
      "- 1.1: getTable *** FAILED ***",
      "- 1.1: getTableOption *** FAILED ***",
      "- 1.1: alterTable(table: CatalogTable) *** FAILED ***",
      "- 1.1: alterTable(dbName: String, tableName: String, table: CatalogTable) *** FAILED ***",
      "- 1.1: alterTable - rename *** FAILED ***",
      "- 1.1: alterTable - change database *** FAILED ***",
      "- 1.1: alterTable - change database and table names *** FAILED ***",
      "- 1.1: listTables(database) *** FAILED ***",
      "- 1.1: listTables(database, pattern) *** FAILED ***",
      "- 1.1: dropTable *** FAILED ***",
      "- 1.1: sql create partitioned table *** FAILED ***",
      "- 1.1: createPartitions *** FAILED ***",
      "- 1.1: getPartitionNames(catalogTable) *** FAILED ***",
      "- 1.1: getPartitions(catalogTable) *** FAILED ***",
      "- 1.1: getPartitionsByFilter *** FAILED ***",
      "- 1.1: getPartition *** FAILED ***",
      "- 1.1: getPartitionOption(db: String, table: String, spec: TablePartitionSpec) *** FAILED ***",
      "- 1.1: getPartitionOption(table: CatalogTable, spec: TablePartitionSpec) *** FAILED ***",
      "- 1.1: getPartitions(db: String, table: String) *** FAILED ***",
      "- 1.1: loadPartition *** FAILED ***",
      "- 1.1: loadDynamicPartitions *** FAILED ***",
      "- 1.1: renamePartitions *** FAILED ***",
      "- 1.1: alterPartitions *** FAILED ***",
      "- 1.1: dropPartitions *** FAILED ***",
      "- 1.1: createFunction *** FAILED ***",
      "- 1.1: functionExists *** FAILED ***",
      "- 1.1: renameFunction *** FAILED ***",
      "- 1.1: alterFunction *** FAILED ***",
      "- 1.1: getFunction *** FAILED ***",
      "- 1.1: getFunctionOption *** FAILED ***",
      "- 1.1: listFunctions *** FAILED ***",
      "- 1.1: dropFunction *** FAILED ***",
      "- 1.1: sql set command *** FAILED ***",
      "- 1.1: sql create index and reset *** FAILED ***",
      "- 1.1: version *** FAILED ***",
      "- 1.1: getConf *** FAILED ***",
      "- 1.1: setOut *** FAILED ***",
      "- 1.1: setInfo *** FAILED ***",
      "- 1.1: setError *** FAILED ***",
      "- 1.1: newSession *** FAILED ***",
      "- 1.1: withHiveState and addJar *** FAILED ***",
      "- 1.1: reset *** FAILED ***",
      "- 1.1: CREATE TABLE AS SELECT *** FAILED ***",
      "- 1.1: Delete the temporary staging directory and files after each insert *** FAILED ***",
      "- 1.1: SPARK-13709: reading partitioned Avro table with nested schema *** FAILED ***",
      "- 1.1: CTAS for managed data source tables *** FAILED ***",
      "- 1.1: Decimal support of Avro Hive serde *** FAILED ***",
      "- 1.1: read avro file containing decimal *** FAILED ***",
      "- 1.1: SPARK-17920: Insert into/overwrite avro table *** FAILED ***",
      "- 1.2: create client *** FAILED ***",
      "- 1.2: createDatabase *** FAILED ***",
      "- 1.2: createDatabase with null description *** FAILED ***",
      "- 1.2: setCurrentDatabase *** FAILED ***",
      "- 1.2: getDatabase *** FAILED ***",
      "- 1.2: databaseExists *** FAILED ***",
      "- 1.2: listDatabases *** FAILED ***",
      "- 1.2: alterDatabase *** FAILED ***",
      "- 1.2: dropDatabase *** FAILED ***",
      "- 1.2: createTable *** FAILED ***",
      "- 1.2: loadTable *** FAILED ***",
      "- 1.2: tableExists *** FAILED ***",
      "- 1.2: getTable *** FAILED ***",
      "- 1.2: getTableOption *** FAILED ***",
      "- 1.2: alterTable(table: CatalogTable) *** FAILED ***",
      "- 1.2: alterTable(dbName: String, tableName: String, table: CatalogTable) *** FAILED ***",
      "- 1.2: alterTable - rename *** FAILED ***",
      "- 1.2: alterTable - change database *** FAILED ***",
      "- 1.2: alterTable - change database and table names *** FAILED ***",
      "- 1.2: listTables(database) *** FAILED ***",
      "- 1.2: listTables(database, pattern) *** FAILED ***",
      "- 1.2: dropTable *** FAILED ***",
      "- 1.2: sql create partitioned table *** FAILED ***",
      "- 1.2: createPartitions *** FAILED ***",
      "- 1.2: getPartitionNames(catalogTable) *** FAILED ***",
      "- 1.2: getPartitions(catalogTable) *** FAILED ***",
      "- 1.2: getPartitionsByFilter *** FAILED ***",
      "- 1.2: getPartition *** FAILED ***",
      "- 1.2: getPartitionOption(db: String, table: String, spec: TablePartitionSpec) *** FAILED ***",
      "- 1.2: getPartitionOption(table: CatalogTable, spec: TablePartitionSpec) *** FAILED ***",
      "- 1.2: getPartitions(db: String, table: String) *** FAILED ***",
      "- 1.2: loadPartition *** FAILED ***",
      "- 1.2: loadDynamicPartitions *** FAILED ***",
      "- 1.2: renamePartitions *** FAILED ***",
      "- 1.2: alterPartitions *** FAILED ***",
      "- 1.2: dropPartitions *** FAILED ***",
      "- 1.2: createFunction *** FAILED ***",
      "- 1.2: functionExists *** FAILED ***",
      "- 1.2: renameFunction *** FAILED ***",
      "- 1.2: alterFunction *** FAILED ***",
      "- 1.2: getFunction *** FAILED ***",
      "- 1.2: getFunctionOption *** FAILED ***",
      "- 1.2: listFunctions *** FAILED ***",
      "- 1.2: dropFunction *** FAILED ***",
      "- 1.2: sql set command *** FAILED ***",
      "- 1.2: sql create index and reset *** FAILED ***",
      "- 1.2: version *** FAILED ***",
      "- 1.2: getConf *** FAILED ***",
      "- 1.2: setOut *** FAILED ***",
      "- 1.2: setInfo *** FAILED ***",
      "- 1.2: setError *** FAILED ***",
      "- 1.2: newSession *** FAILED ***",
      "- 1.2: withHiveState and addJar *** FAILED ***",
      "- 1.2: reset *** FAILED ***",
      "- 1.2: CREATE TABLE AS SELECT *** FAILED ***",
      "- 1.2: Delete the temporary staging directory and files after each insert *** FAILED ***",
      "- 1.2: SPARK-13709: reading partitioned Avro table with nested schema *** FAILED ***",
      "- 1.2: CTAS for managed data source tables *** FAILED ***",
      "- 1.2: Decimal support of Avro Hive serde *** FAILED ***",
      "- 1.2: read avro file containing decimal *** FAILED ***",
      "- 1.2: SPARK-17920: Insert into/overwrite avro table *** FAILED ***",
      "- 2.0: create client *** FAILED ***",
      "- 2.0: createDatabase *** FAILED ***",
      "- 2.0: createDatabase with null description *** FAILED ***",
      "- 2.0: setCurrentDatabase *** FAILED ***",
      "- 2.0: getDatabase *** FAILED ***",
      "- 2.0: databaseExists *** FAILED ***",
      "- 2.0: listDatabases *** FAILED ***",
      "- 2.0: alterDatabase *** FAILED ***",
      "- 2.0: dropDatabase *** FAILED ***",
      "- 2.0: createTable *** FAILED ***",
      "- 2.0: loadTable *** FAILED ***",
      "- 2.0: tableExists *** FAILED ***",
      "- 2.0: getTable *** FAILED ***",
      "- 2.0: getTableOption *** FAILED ***",
      "- 2.0: alterTable(table: CatalogTable) *** FAILED ***",
      "- 2.0: alterTable(dbName: String, tableName: String, table: CatalogTable) *** FAILED ***",
      "- 2.0: alterTable - rename *** FAILED ***",
      "- 2.0: alterTable - change database *** FAILED ***",
      "- 2.0: alterTable - change database and table names *** FAILED ***",
      "- 2.0: listTables(database) *** FAILED ***",
      "- 2.0: listTables(database, pattern) *** FAILED ***",
      "- 2.0: dropTable *** FAILED ***",
      "- 2.0: sql create partitioned table *** FAILED ***",
      "- 2.0: createPartitions *** FAILED ***",
      "- 2.0: getPartitionNames(catalogTable) *** FAILED ***",
      "- 2.0: getPartitions(catalogTable) *** FAILED ***",
      "- 2.0: getPartitionsByFilter *** FAILED ***",
      "- 2.0: getPartition *** FAILED ***",
      "- 2.0: getPartitionOption(db: String, table: String, spec: TablePartitionSpec) *** FAILED ***",
      "- 2.0: getPartitionOption(table: CatalogTable, spec: TablePartitionSpec) *** FAILED ***",
      "- 2.0: getPartitions(db: String, table: String) *** FAILED ***",
      "- 2.0: loadPartition *** FAILED ***",
      "- 2.0: loadDynamicPartitions *** FAILED ***",
      "- 2.0: renamePartitions *** FAILED ***",
      "- 2.0: alterPartitions *** FAILED ***",
      "- 2.0: dropPartitions *** FAILED ***",
      "- 2.0: createFunction *** FAILED ***",
      "- 2.0: functionExists *** FAILED ***",
      "- 2.0: renameFunction *** FAILED ***",
      "- 2.0: alterFunction *** FAILED ***",
      "- 2.0: getFunction *** FAILED ***",
      "- 2.0: getFunctionOption *** FAILED ***",
      "- 2.0: listFunctions *** FAILED ***",
      "- 2.0: dropFunction *** FAILED ***",
      "- 2.0: sql set command *** FAILED ***",
      "- 2.0: sql create index and reset *** FAILED ***",
      "- 2.0: version *** FAILED ***",
      "- 2.0: getConf *** FAILED ***",
      "- 2.0: setOut *** FAILED ***",
      "- 2.0: setInfo *** FAILED ***",
      "- 2.0: setError *** FAILED ***",
      "- 2.0: newSession *** FAILED ***",
      "- 2.0: withHiveState and addJar *** FAILED ***",
      "- 2.0: reset *** FAILED ***",
      "- 2.0: CREATE TABLE AS SELECT *** FAILED ***",
      "- 2.0: Delete the temporary staging directory and files after each insert *** FAILED ***",
      "- 2.0: SPARK-13709: reading partitioned Avro table with nested schema *** FAILED ***",
      "- 2.0: CTAS for managed data source tables *** FAILED ***",
      "- 2.0: Decimal support of Avro Hive serde *** FAILED ***",
      "- 2.0: read avro file containing decimal *** FAILED ***",
      "- 2.0: SPARK-17920: Insert into/overwrite avro table *** FAILED ***",
      "- 2.1: create client *** FAILED ***",
      "- 2.1: createDatabase *** FAILED ***",
      "- 2.1: createDatabase with null description *** FAILED ***",
      "- 2.1: setCurrentDatabase *** FAILED ***",
      "- 2.1: getDatabase *** FAILED ***",
      "- 2.1: databaseExists *** FAILED ***",
      "- 2.1: listDatabases *** FAILED ***",
      "- 2.1: alterDatabase *** FAILED ***",
      "- 2.1: dropDatabase *** FAILED ***",
      "- 2.1: createTable *** FAILED ***",
      "- 2.1: loadTable *** FAILED ***",
      "- 2.1: tableExists *** FAILED ***",
      "- 2.1: getTable *** FAILED ***",
      "- 2.1: getTableOption *** FAILED ***",
      "- 2.1: alterTable(table: CatalogTable) *** FAILED ***",
      "- 2.1: alterTable(dbName: String, tableName: String, table: CatalogTable) *** FAILED ***",
      "- 2.1: alterTable - rename *** FAILED ***",
      "- 2.1: alterTable - change database *** FAILED ***",
      "- 2.1: alterTable - change database and table names *** FAILED ***",
      "- 2.1: listTables(database) *** FAILED ***",
      "- 2.1: listTables(database, pattern) *** FAILED ***",
      "- 2.1: dropTable *** FAILED ***",
      "- 2.1: sql create partitioned table *** FAILED ***",
      "- 2.1: createPartitions *** FAILED ***",
      "- 2.1: getPartitionNames(catalogTable) *** FAILED ***",
      "- 2.1: getPartitions(catalogTable) *** FAILED ***",
      "- 2.1: getPartitionsByFilter *** FAILED ***",
      "- 2.1: getPartition *** FAILED ***",
      "- 2.1: getPartitionOption(db: String, table: String, spec: TablePartitionSpec) *** FAILED ***",
      "- 2.1: getPartitionOption(table: CatalogTable, spec: TablePartitionSpec) *** FAILED ***",
      "- 2.1: getPartitions(db: String, table: String) *** FAILED ***",
      "- 2.1: loadPartition *** FAILED ***",
      "- 2.1: loadDynamicPartitions *** FAILED ***",
      "- 2.1: renamePartitions *** FAILED ***",
      "- 2.1: alterPartitions *** FAILED ***",
      "- 2.1: dropPartitions *** FAILED ***",
      "- 2.1: createFunction *** FAILED ***",
      "- 2.1: functionExists *** FAILED ***",
      "- 2.1: renameFunction *** FAILED ***",
      "- 2.1: alterFunction *** FAILED ***",
      "- 2.1: getFunction *** FAILED ***",
      "- 2.1: getFunctionOption *** FAILED ***",
      "- 2.1: listFunctions *** FAILED ***",
      "- 2.1: dropFunction *** FAILED ***",
      "- 2.1: sql set command *** FAILED ***",
      "- 2.1: sql create index and reset *** FAILED ***",
      "- 2.1: version *** FAILED ***",
      "- 2.1: getConf *** FAILED ***",
      "- 2.1: setOut *** FAILED ***",
      "- 2.1: setInfo *** FAILED ***",
      "- 2.1: setError *** FAILED ***",
      "- 2.1: newSession *** FAILED ***",
      "- 2.1: withHiveState and addJar *** FAILED ***",
      "- 2.1: reset *** FAILED ***",
      "- 2.1: CREATE TABLE AS SELECT *** FAILED ***",
      "- 2.1: Delete the temporary staging directory and files after each insert *** FAILED ***",
      "- 2.1: SPARK-13709: reading partitioned Avro table with nested schema *** FAILED ***",
      "- 2.1: CTAS for managed data source tables *** FAILED ***",
      "- 2.1: Decimal support of Avro Hive serde *** FAILED ***",
      "- 2.1: read avro file containing decimal *** FAILED ***",
      "- 2.1: SPARK-17920: Insert into/overwrite avro table *** FAILED ***",
      "- SPARK-18355 Read data from a hive table with a new column - orc *** FAILED ***",
      "- SPARK-18355 Read data from a hive table with a new column - parquet *** FAILED ***",
      "- create Hive-serde table and view with unicode columns and comment *** FAILED ***",
      "- basic DDL using locale tr - caseSensitive true *** FAILED ***",
      "- SPARK-21617: ALTER TABLE for non-compatible DataSource tables *** FAILED ***",
      "- SPARK-21617: ALTER TABLE for Hive-compatible DataSource tables *** FAILED ***",
      "- SPARK-21617: ALTER TABLE for Hive tables *** FAILED ***",
      "- SPARK-21617: ALTER TABLE with incompatible schema on Hive-compatible table *** FAILED ***",
      "- shaded Protobuf *** FAILED ***",
      "- Forbidden Dependencies *** FAILED ***",
      "- Read/Write Hive PARQUET serde table *** FAILED ***",
      "- Read/Write Hive ORC serde table *** FAILED ***",
      "- SPARK-19459/SPARK-18220: read char/varchar column written by Hive *** FAILED ***",
      "- SPARK-8020: set sql conf in spark conf *** FAILED ***",
      "- SPARK-9757 Persist Parquet relation with decimal column *** FAILED ***",
      "- SPARK-16901: set javax.jdo.option.ConnectionURL *** FAILED ***"
    ]
  },
  "sql/hive-thriftserver": {
    "attributes": {
      "Succeeded": 40.0,
      "Failed": 0.0,
      "Skipped": 2.0,
      "Pending": 0.0,
      "Aborted_tests": NaN
    },
    "Failed_tests": [
      NaN
    ]
  },
  "resource-managers/yarn": {
    "attributes": {
      "Succeeded": NaN,
      "Failed": NaN,
      "Skipped": NaN,
      "Pending": NaN,
      "Aborted_tests": "*** RUN ABORTED ***"
    },
    "Failed_tests": [
      NaN
    ]
  }
}